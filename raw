Prediction of Diabetes Using Logistic Regression

Modeling

Ali Rajpoot       December 23, 2023

Abstract

This project explores the prediction of Diabetes as the prevalence of diabetes has been on the rise globally, so the need for predictive models is needed to identify individuals at risk. This project utilizes Logistic Regression and other statistical methods to develop a predictive model based on key parameters such as the levels of Glucose, Blood Pressure, Insulin, Skin Thickness, BMI, et cetera.

1  Introduction

Diabetes Mellitus, or as commonly referred to as Diabetes, poses a significant global health challenge. Diabetes is a major cause of blindness, kidney failures, heart attacks, stroke, and lower limb amputation. Due to the health risks that

it carries, healthcare organizations are now using Machine Learning Techniques, such as Predictive Modeling in healthcare. To intervene in the timely nature of diabetes, predictive modeling has been used to accurately identify individuals at risk and variables that impact it the most.

The motivation behind this stems from rising prevalence of Diabetes and its associated health complications. Detecting it early and intervention can play a pivotal role in treating it in earlier stages. Logistic regression, a widely used statistical technique for binary classification, will be used in understanding the relationships between different risks with the likelihood of diabetes.

The primary objective of this project is to investigate the effectiveness of lo- gistic regression in predicting Diabetes and to decipher key contributing factors that can lead to Diabetes.

2  The Collection of Data

According to International Diabetes Federation(IDF), the number of diabetic patients is expected to rise to 643 million by 2030, compared to 537 million as of 2021. Statistics as such is what prompted me to pursue this study further and investigate into samples that are mid-sized to see the impact of predictors on the outcome of Diabetes.

The data was uploaded on Kaggle and was initially collected and made available by ”National Institute of Diabetes and Digestive and Kidney Diseases” as part of the PIMA Indians Diabetes Database. The data contains the study of women over ages 21 and several constraints were placed on the selection of instances from a larger database.

3  Exploratory Data Analysis(EDA)

Exploratory Data Analysis(EDA) is an analysis approach that identifies general trends within the data. This is usually the first step in regression modeling especially if the data hasn’t been cleaned yet. From the initial examination of the data, we gather that there are 769 rows and 9 columns, giving it a total of 6921 entries. The nine columns include the predictors and the response vari- able(”Outcome”) for this dataset. It’s better to represent the initial distribution

of the dataset with the respective column names graphically:

![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.001.png)

Figure 1: Distribution of the 9 columns

The distribution seems normal with minor anomalies, upon further inves-      tigation, we tend to see the presence of 0 values in the Pregnancies, Age, et cetera columns that will serve as the predictor variables which are technically      NAN values so we will replace them with the mean of the column one-by-one.    It’s done to preserve the sample size, and avoid any biased estimates. The      frequencies after switching the NAN values with the mean are given below:

![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.002.png)

Figure 2: Frequency Distribution of the predictors

The existence of Outliers was minimal so we did not exclude them from the dataset. Lastly, we look at the correlation matrix in the earlier stages of our analysis in order to get a better understanding of the correlation that exists between our predictors and the Outcome variable.

![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.003.png)

Figure 3: Correlation Matrix

According to the correlation matrix between the variables, Glucose has a value of 0.493 with respect to Outcome, which means that it is most likely going to be added in the final model as the correlation factor is high.

4  Exploring Factors Influencing Diabetes

Our question that needs to be answered in terms of this analysis, as the title suggests, we are exploring factors that are influencing the outcome of Diabetes. Some of the questions that we are answering in this report with the help of regression are common in nature. The big question that comes in mind is ”What is the likelihood of a diabetic outcome based on the values of the predictor variables such as Pregnancies, Glucose, Age”, et cetera. We can also word it differently such as ”How do the variables contribute to the probability of an individual having Diabetes as opposed to not having Diabetes?”

1. A Logistic Regression Approach

Our approach towards solving the problem we mentioned earlier is Logistic Regression. With multiple explanatory variables, model with k predictors is

π(x)

logit{π(x)} = log1 − π(x) = α + β1x1 + β2 2 + ... + βkxk x

Alternatively,

π(x) = exp(α + β1x1 + β2x2 + ... + βkxk)

1 + exp(α + β1x1 + β2x2 + ... + βkxk)

Before we started to model, we split the data into training and testing sets. We split the Outcome variable with 70% utilization for the training set and the remaining 30% for the testing set. This is called cross-validation. The rea- son to do this is to evaluate how well the model generalizes to new, unseen data.

The first modeling that we do is a glm function which models the other 9 predictors against the Outcome response variable. The results of the first mod- eling are given in the following tables:

(a) Intercept, Coefficient Predic- ![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.004.png)![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.005.png)tors (b) OR, 95% CI, p-value

Figure 4: Regression Model Output

From the output above, we notice that the AIC = 510 and the p-values          suggest that our assumption about Glucose happens to be correct, while Blood- Pressure, SkinThickness, Insulin, Age have higher p-values than the common    level of significance that we choose, so safe to say that they can be dropped in

the reduced model.

Next, we aim for a reduced model which is a simpler version of the full model, including a subset of predictors. It is significant as it identifies the important variables, simplifies the model, and improves interpretability. We use a method called Stepwise Selection Feature which runs backward and forward selec- tion features and presents us with a reduced model with the smallest AIC. For

this problem, the predictor variables that stepwise selection feature chose are: Pregnancies, Glucose, BMI, DiabetesPedigreeFunction.

Figure 5: Reduced Model Output![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.006.jpeg)

Hence, this is the reduced model with the lowest AIC.The model with the lowest AIC is most favorable because lower AIC values suggest a better trade-off between explaining the data and avoiding complexity.

To compare the Full and Reduced Model, we use Analysis of Deviance(AoD) and Likelihood Ratio Test(LRT) to test the two models. The hypothesis:

H0 : The simpler model is good enough

Ha : The simpler model is not good enough

Per the output, the p-value of Chi-squared test signify that the value is equiv- alent to 0.533, so we fail to reject the null hypothesis and conclude that the simpler model fits the data nearly as well as the more complex model. The output of the LRT is given below:

![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.007.png)

Figure 6: LRT Results

2. Model Evaluation

The next step will be model evaluation under the reduced model which fits the data better. We initiate this stage by making predictions on the training and testing sets for the reduced model. Then, we convert probability predictions to binary based on a threshold of 0.5. We use confusion matrix to check for Ac- curacy, Sensitivity and Specificity. The Accuracy for the training model

is 77%, Sensitivity 55%, and Specificity 88%.

No Yes No![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.008.png)![ref1] 310 84 Yes 41 103![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.010.png)

Similarly, for testing set, we have the following table:

No Yes No![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.011.png)![ref1] 134 27 Yes 16 53![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.012.png)

The Accuracy for the testing model is 81%, Sensitivity 89%, and Specificity 66%. The higher accuracy and sensitivity suggests that the model will work well under the unseen data. We can also use ROC(AUC) method to see the outcome

of the testing and training sets. We have the following curves for the two sets:

![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.013.jpeg)

Figure 7: ROC(AUC)

The curves show the ordinary ROC with an average AUC meaning that this model performs better than random guessing. It is not the perfect model as the Accuracy of the model lies within 80% range but some improvements can be made to ensure that the model is stronger than it is now. That would require adding more data than the dataset that we used for this analysis.

5  Conclusion
1. Methods

We gathered data, performed exploratory data analysis to see any evidence of multicollinearity, presence of outliers, and overall distribution. We used cross- validation to split the data into training and testing sets. Then we modeled with all the predictors, used stepwise selection feature to get the model with the lowest AIC and predicted probabilities to evaluate the model. We further went ahead with creating confusion matrices to evaluate the model using accuracy, specificity, and sensitivity. Lastly, ROC with AUC was utilized to see the testing and training sets’ evaluation around Sensitivity and Specificity.

2. Predicting Diabetes

In terms of the initial question that we had, how do we discover and find early signs of diabetes and the conditions or features that can detect prediabetes phase? We conclude by stating that the significant predictors for Diabetes Outcome are Pregnancies, Glucose, BMI, and PedigreeFunction. The log odds suggest that higher BMI, Glucose, and PedigreeFunction are indicators of a positive outcome of Diabetes. In terms of Pregnancies, it is quite possible that a temporary form of Diabetes might be present, but since this data was collected in majority women, this factor was added to test whether the effects of Pregnancies later contribute to Diabetes outcome.In terms of moving further, one can collect more data and test out the model efficiencies. Collection of a diverse data from multiple sources, sorting them together and train it to test further about how the new data fits the model.

8

6  Appendix

Jagadish, K. (2019, May 7). Diabetics prediction using logistic regression. Kag- gle. https://www.kaggle.com/datasets/kandij/diabetes-dataset

1  # Your R code goes here![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.014.png)
1  # Final Project

3

4  # Loading the required libraries
4  install.packages("dplyr")
4  install.packages("janitor")
4  install.packages("ggplot2")
4  install.packages("ggthemes")
4  install.packages("cowplot")
4  install.packages("stringr")
4  install.packages("ggcorrplot")
4  install.packages("GGally")
4  install.packages("rlang")
4  install.packages("caret")
4  install.packages("MASS")
4  install.packages("car")
4  install.packages("tidyr")
4  install.packages("caTools")
4  install.packages("finalfit")
4  install.packages("lmtest")

21

22  library(dplyr)
22  library(janitor)
22  library(ggplot2)
22  library(ggthemes)
22  library(cowplot)
22  library(stringr)
22  library(ggcorrplot)
22  library(GGally)
22  library(rlang)
22  library(caret)
22  library(MASS)
22  library(car)
22  library(tidyr)
22  library(lmtest)
22  library(caTools)
22  library(finalfit)
22  # Loading the data:
22  data\_raw <- read.csv("C:/Users/alira/Documents/Advanced Data Analysis - Baruch/FP\_diabetes.csv")
22  data\_raw[,-1]

41

42

43

44  # Checking the dimension of the dataset
44  dim(data\_raw)

46



|# Data cleaning and Preparation|
| - |
|summary(data\_raw)|
|str(data\_raw)|
||
||
|# Replacing 0’s of few variables into Nan|
|data\_raw[c("Pregnancies", "Glucose", "BloodPressure", "|
|SkinThickness", "Insulin", "BMI", "|
|DiabetesPedigreeFunction", "Age")][data\_raw[c("|
|Pregnancies", "Glucose", "BloodPressure", "SkinThickness"|
|, "Insulin", "BMI", "DiabetesPedigreeFunction", "Age")|
|]==0] <- NA|
||
|# Replacing NA values with Mean, to preserve central|
|tendency and suitable imputation for categorical data|
|# This code is a function to find Mean of a column.|
|Mean <- function(x){|
|mean\_value <- mean(x, na.rm = TRUE)|
|if (is.na(mean\_value)) {|
|warning("All values in the column are NA.")|
|}|
|replace(x, is.na(x), mean\_value)|
|}|
|# Filling the nan values with "Mean"|
|data\_raw <- data\_raw %>%|
|mutate\_all(Mean)|
||
|head(data\_raw ,15)|
||
|str(data\_raw)|
||
|# Exploratory Data Analysis(EDA)|
|set.seed(123)|
|data\_long <- gather(data\_raw, key = "variable", value="value|
|")|
||
|ggplot(data\_long, aes(x=value, fill=variable)) +|
|geom\_bar(position = "dodge", stat = "count") +|
|facet\_wrap(~variable , scales = "free\_x") +|
|scale\_y\_log10() +|
|scale\_x\_log10(100) +|
|labs(title = "Frequency",|
|x = "Value",|
|y = "Frequency") +|
|theme\_minimal() +|
|theme(axis.text.x = element\_text(angle=50, hjust=1))|
||
|# Histogram to check outliers|
|options(repr.plot.width=10, repr.plot.height=7)|
|hist(data\_raw $Pregnancies , main="Pregnancies Histogram", col|
|= "red")|
|hist(data\_raw $Glucose , main="Glucose Histogram", col="green"|
|)|
|hist(data\_raw $BloodPressure , main="BP Histogram", col="brown|

47 ![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.015.png)48 49 50 51 52 53 

54 55 

56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 

75 76 77 78 

79 80 81 82 83 84 85 86 87 88 89 

90 91 



|")|
| - |
||
|# Barplot to view the distribution of the four variables..|
|int\_vars <- c(’Pregnancies’, ’BloodPressure’, ’SkinThickness|
|’, ’Age’)|
|for (var in int\_vars) {|
|# Create a ggplot for each variable|
|p <- ggplot(data\_raw, aes\_string(x = var, fill = "Outcome"|
|)) +|
|geom\_bar(position = "dodge") +|
|labs(title = var) +|
|theme\_minimal()|
||
|# Print the ggplot|
|print(p)|
|}|
||
|par(mfrow = c(1, 1), oma = c(0, 0, 0, 0))|
||
|# To check outliers|
|options(repr.plot.width=10, repr.plot.height=7)|
|hist(data\_raw $Pregnancies , main="Pregnancies Histogram", col|
|="red", xlab="Pregnancies", ylab = "Count")|
|hist(data\_raw $BloodPressure , main="BP Histogram", col="|
|purple", xlab="BP", ylab="Count")|
|hist(data\_raw $SkinThickness , main="SkinThickness", col="|
|yellow", xlab="SkinThickness", ylab="Count")|
|hist(data\_raw $Age, main="Age", col="blue", xlab="Age", ylab=|
|"Count")|
||
|# Correlation Matrix Between Numeric Variables|
|ggcorrplot(round(cor(data\_raw[, c(1,3,4,8)]), 2), title="|
|Corr Matrix", hc.order=T, lab=T,|
|type="lower", lab\_size=15) + theme(plot.title=|
|element\_text(hjust=0.5, size=25),|
|axis.text.y =|
|element\_|
|text(size|
|=25), axis.|
|text.x=|
|element\_text|
|(size=25)|
|, legend.|
|text=|
|element\_|
|text(size|
|=20))|
||
|options(repr.plot.width=15, repr.plot.height=9)|
||
|theme\_1 <- theme(plot.background = element\_rect(fill="#|
|F5FFFA", color="darkblue"),|
|plot.title = element\_text(size=25, hjust|
|=.5),|

92 ![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.016.png)93 94 

95 96 97 

98 99 100 101 102 103 104 105 106 107 108 109 110 

111 112 113 

114 115 116 

117 118 

119 

120 121 122 123 

124 

125 axis.title.x = element\_text(size=25, color![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.017.png)

- "black"),

126 axis.title.y = element\_text(size=25, color

- "black"),

127 axis.text.x = element\_text(size=20),

128 axis.text.y = element\_text(size=20),

129 legend.position = "top",

130 legend.text = element\_text(size=20),

131 legend.title = element\_text(size=20)) 132 Outcome\_f <- as.factor(data\_raw $Outcome)

133

134 ggpairs(data\_raw, columns = c(1,3,4,8), ggplot2::aes(color = Outcome\_f)) +

135 theme\_economist()+

136 theme\_1

137

138

139

140

141

142  # Splitting Data into Train(70%) and Test(30%)
142  set.seed(123)
142  data\_raw <- data\_raw %>%

145 mutate(Outcome = as.factor(Outcome)) 146 str(data\_raw)

147

148 split <- createDataPartition(y = data\_raw $Outcome , p = 0.7, list = F)

149

150  training\_set <- data\_raw[split ,]
150  testing\_set <- data\_raw[-split ,]

152

153  table(training\_set $Outcome)
153  table(testing\_set $Outcome)
153  # Both train and test data are perfectly balanced

156

157  # Corr
157  ggpairs(data\_raw, lower= list(continuous="smooth"))

159

160  # Building Logistic Regression Model
160  mdl\_1 <- glm(Outcome~., data = training\_set, family=binomial (link="logit"))

162

163  summary(mdl\_1)
163  #Table creation
163  install.packages("gtsummary")
163  library(gtsummary)
163  install.packages("stargazer")
163  library(stargazer)
163  #Wald Test
163  wald\_result <- waldtest(mdl\_1, "BloodPressure")
163  summary(wald\_result)
163  tbl\_regression(mdl\_1, exponentiate = TRUE)

173



|# Stepwise Feature Selection Model|
| - |
|mdl\_2 <- stepAIC(mdl\_1, direction = "both")|
|summary(mdl\_2)|
|formula(mdl\_2)|
|#Table|
|tbl\_regression(mdl\_2, exponentiate=TRUE)|
|stargazer(mdl\_2, type = "html", title = "Logistic Regression|
|Results", out="C:/Users/alira/Desktop/Final Project.html|
|")|
||
|mdl\_3 <- glm(formula = Outcome ~ Pregnancies + Glucose + BMI|
|+ DiabetesPedigreeFunction + Glucose:BMI,|
|family = binomial(link = "logit"), data =|
|training\_set)|
||
||
||
||
|# Checking for multicollinearity in the second model|
|(vif\_vars <- as.data.frame(vif(mdl\_2)))|
||
|# Since the VIF(Variance Inflation Factor) is less than|
|5-10, these variables are good to work with.|
||
|#Model Comparison|
|#anova(mdl\_2, mdl\_1, test="Chisq")|
|lr\_test <- lrtest(mdl\_2, mdl\_1)|
|print(lr\_test)|
|# Assuming mdl\_full and mdl\_reduced are your logistic|
|regression models|
||
|# Install and load the necessary packages if not already|
|installed|
|# install.packages(c("lmtest", "stargazer"))|
|library(lmtest)|
|library(stargazer)|
||
|# Create a summary table|
|summary\_table <- stargazer(|
|lr\_test,|
|title = "Likelihood Ratio Test Summary",|
|type = "html", # Specify the output type (HTML for a more|
|visually appealing table)|
|out = "C:/Users/alira/Desktop/table.html", # Save the|
|HTML table to a file (optional)|
|style = "AER", # Use a style theme (e.g., "AER" for a|
|clean and professional look)|
|single.row = TRUE, # Display coefficients in a single row|
|header = FALSE, # Hide the table header|
|digits = 3 # Set the number of digits to display|
|)|
||
|# Print the summary table|
|cat(summary\_table)|

174 ![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.018.png)175 176 177 178 179 

180 

181 182 

183 

184 185 186 187 188 189 190 191 

192 193 194 195 196 197 

198 199 

200 201 202 203 

204 205 206 207 208 

209 210 

211 212 213 214 215 216 

217 



||
| :- |
|library(caret)|
|library(pROC)|
||
|# Make predictions on the testing set for mdl\_2|
||
||
|# Convert probability predictions to binary (0 or 1) based|
|on a threshold (e.g., 0.5)|
|threshold <- 0.5|
|binary\_pred\_mdl\_3 <- ifelse(pred\_mdl\_3 >= threshold , 1,0)|
|binary\_pred\_train\_mdl\_3 <- ifelse(pred\_train\_mdl\_3 >=|
|threshold , 1, 0)|
||
|conf\_matrix\_train\_mdl\_3 <- confusionMatrix(data = binary\_|
|pred\_train\_mdl\_3, reference = training\_set $Outcome ,|
|levels = c(0, 1))|
||
|str(training\_set $Outcome)|
|str(testing\_set $Outcome)|
||
|unique(training\_set $Outcome)|
|unique(testing\_set $Outcome)|
||
||
|# Confusion matrix for mdl\_2|
|conf\_matrix\_mdl\_2 <- confusionMatrix(data = binary\_pred\_mdl\_|
|2, reference = testing\_set $Outcome , levels = c(0, 1))|
||
|# Model Evaluation Using Testing|
|pred\_test\_mdl\_2 <- predict(mdl\_2, newdata = testing\_set,|
|type = "response")|
|pred\_train\_mdl\_2 <- predict(mdl\_2, newdata = training\_set,|
|type = "response")|
||
|# Check model train data|
|pred\_trainOut <- factor(ifelse(pred\_train\_mdl\_2 >= 0.50, "|
|Yes", "No"))|
|actual\_trainOut <- factor(ifelse(training\_set $Outcome==1, "|
|Yes", "No"))|
||
|table(actual\_trainOut , pred\_trainOut)|
||
|pred\_testOut <- factor(ifelse(pred\_test\_mdl\_2 >= 0.5, "Yes",|
|"No"))|
|actual\_testOut <- factor(ifelse(testing\_set $Outcome==1, "Yes|
|", "No"))|
||
|table(actual\_Out, pred\_Out)|
||
|# Confusion Matrix and Stats:|
|cm1 <- caret::confusionMatrix(pred\_trainOut , actual\_trainOut|
|, positive = "No")|
|cm2 <- caret::confusionMatrix(pred\_Out, actual\_Out, positive|

218 ![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.019.png)219 220 221 222 223 224 225 

226 227 228 

229 230 

231 232 233 234 235 236 237 238 239 240 

241 242 243 

244 

245 246 247 

248 

249 250 251 252 

253 

254 255 256 257 258 

259 

- "No")![](Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.020.png)

260

261  install.packages("xtable")
261  library(xtable)
261  conf\_matrix\_df <- as.table(cm2)
261  conf\_matrix\_table <- xtable(conf\_matrix\_df)
261  print.xtable(conf\_matrix\_table, include.rownames = TRUE)

266

267  # More Methods
267  library(pROC)
267  roc\_curve\_test <- roc(testing\_set $Outcome , pred\_test\_mdl\_2)
267  plot(roc\_curve, main = "ROC Curve", col = "blue", lwd = 2)
267  roc\_curve\_train <- roc(training\_set $Outcome , pred\_train\_mdl\_ 2)
267  plot(roc\_curve\_train, main = "ROC Curve", col = "red", lwd =2)

273

274  plot(roc\_curve\_test, col = "blue", lwd = 2, main = "ROC Curve", sub = "Testing Set vs Training Set", col.main = " black", col.sub = "darkgray", lty = 1)
274  plot(roc\_curve\_train, col = "red", lwd = 2, add = TRUE)
274  legend("bottomright", legend = c("Testing Set", "Training Set"), col = c("blue", "red"), lty = 1:1, cex = 0.8)

277

278  #Regularization
278  install.packages("glmnet")
278  library(glmnet)
278  X\_train <- model.matrix(~ . - Outcome , data = training\_set)
278  Y\_train <- training\_set $Outcome

283

284 cv\_mdl <- cv.glmnet(X\_train, Y\_train, family="binomial", alpha = 1)

285

286  plot(cv\_mdl)
286  best\_lambda <- cv\_mdl $lambda.min

288

289  best\_model <- glmnet(X\_train, Y\_train, family = "binomial", alpha = 1, lambda = best\_lambda)
289  X\_test <- model.matrix(~ . - Outcome , data = testing\_set)
289  summary(best\_model)
289  predictions <- predict(best\_model, newx = X\_test, s = best\_ lambda , type = "response")
289  predictions <- predict(best\_model, newx = X\_test, s = best\_ lambda , type = "response")
289  roc\_curve\_test\_2 <- roc(testing\_set $Outcome , predictions)

Listing 1: Final Project R Code
18

[ref1]: Aspose.Words.74dc3b03-65b3-4f44-bc74-63d8421533ca.009.png
